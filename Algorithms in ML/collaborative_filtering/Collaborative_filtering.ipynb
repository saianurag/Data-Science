{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1>Recommender systems using Collaborative filtering</h1>\n",
    "\n",
    "___\n",
    "\n",
    "A Recommender System is a class of algorithms which aims at enhancing user experience by producing refined and relevant suggestions specific to the target user. \n",
    "\n",
    "Many commercial applications benefit from the use of such algorithms.\n",
    "\n",
    "> - Video/Song Sharing Services like <u>Youtube, Netflix, Gaana, Saavan</u>, for suggesting content.\n",
    "> - Social Media Websites like <u>Facebook, Twitter, Instagram</u>, for suggesting other links and advertisements.\n",
    "> - E-commerce sites like <u>Amazon, Flipkart</u>, for suggested future purchases.\n",
    "> - Matrimonial & Dating Sites like <u>Jeevansathi, Tinder</u>, for suggesting suitable matches. \n",
    "> - News, Blog & Q&A sites like <u>Forbes, Medium, Quora</u>, for suggesting future reads.\n",
    "\n",
    "There are 2 types of Reccomender Systems\n",
    "\n",
    "- <b>Collaborative Filtering</b> : \n",
    "\n",
    "This approach relies on user's past behaviour. \n",
    "\n",
    "Collaborative Filtering is the most common technique used when it comes to building intelligent recommender systems that can learn to give better recommendations as more information about users is collected.\n",
    "\n",
    "Most websites like Amazon, YouTube, and Netflix use collaborative filtering as a part of their sophisticated recommendation systems. You can use this technique to build recommenders that give suggestions to a user on the basis of the likes and dislikes of similar users.\n",
    "  \n",
    "   > - The model finds n users that have a similar taste as the target user. \n",
    "   > - A score is calculate for all items that the target user has not rated using the rating of similar users. \n",
    "   > - Top N items based on the calculated score are suggested to the target user.\n",
    "  \n",
    "- <b>Content-based Filtering</b> : This approach relies on item properties. \n",
    "\n",
    "   > - The model finds n users that have a similar taste as the target user. \n",
    "   > - A score is calculate for all items that the target user has not rated using the rating of similar users. \n",
    "   > - Top N items based on the calculated score are suggested to the target user.\n",
    "   \n",
    "A final commercial solution will have a mix of both kinds of techniques in many different forms.\n",
    "\n",
    "\n",
    "## Can you think of some problems in building an accurate Reccomendation System?\n",
    "\n",
    " - User Preferences can change with time.\n",
    "- Not just ratings but search history also needs to be modelled.\n",
    "- Even the most active users usually rate very few items. The data is very sparse.\n",
    "- For new users and items, the suggestions will not be good unless substantial information is available to build a user profile. Often, a naive approach of suggesting the most popular items is followed in the beginning.\n",
    "- Data collection is very important for building a good reccomendation engine. Some sites ask users to pick some preferences while creating a profile. \n",
    "- Feedbacks shared by users has to be analysed for sentiment analysis and aspect analysis using text analytics.\n",
    "- Computation requirement is high.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Therefore, there is no single technique that will give great reccomendations. The design is complex and there is constant research towards developing a more personalised reccomendation engine.</b>\n",
    "</div>    \n",
    "\n",
    "___\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>FUN FACT</b> \n",
    "\n",
    "From 2006 to 2009, Netflix sponsored a competition, offering a grand prize of $1,000,000 to the team that could take an offered dataset of over 100 million movie ratings and return recommendations that were 10 percent more accurate than those offered by the company's existing recommender system. \n",
    "\n",
    "On 21 September 2009, the grand prize of US$1,000,000 was given to the BellKor's Pragmatic Chaos team using tiebreaking rules.\n",
    "\n",
    "The most accurate algorithm in 2007 used an ensemble method of 107 different algorithmic approaches, blended into a single prediction. As stated by the winners, Bell et al.,\n",
    "\n",
    "> Predictive accuracy is substantially improved when blending multiple predictors. Our experience is that most efforts should be concentrated in deriving substantially different approaches, rather than refining a single technique. Consequently, our solution is an ensemble of many methods.\n",
    "\n",
    "Source : Wikipedia\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "### We will be using suprise package, `surprise` is a python package used to make recommender systems\n",
    "http://surpriselib.com/\n",
    "<br>https://github.com/NicolasHug/Surprise\n",
    "<br>http://surprise.readthedocs.io/en/stable/index.html\n",
    "    \n",
    "> - It deals with explicit ratings only.\n",
    "- This is available as part of sckit learn library\n",
    "\n",
    "### Install surprise package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in /Users/sujitdhanuka/opt/anaconda3/lib/python3.7/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /Users/sujitdhanuka/opt/anaconda3/lib/python3.7/site-packages (from scikit-surprise) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/sujitdhanuka/opt/anaconda3/lib/python3.7/site-packages (from scikit-surprise) (1.5.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/sujitdhanuka/opt/anaconda3/lib/python3.7/site-packages (from scikit-surprise) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/sujitdhanuka/opt/anaconda3/lib/python3.7/site-packages (from scikit-surprise) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>We will use the publicly available [Jokes](http://eigentaste.berkeley.edu/dataset/) Dataset. Check the `URL` [Jokes](http://eigentaste.berkeley.edu/dataset/) for file more details about the dataset.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Jokes Dataset\n",
    "\n",
    "This dataset is available at http://eigentaste.berkeley.edu/dataset/\n",
    "\n",
    "**Over 100,000 new ratings from 59,132 total users.**\n",
    "\n",
    "`jester_jokes.tsv` contains the text of the jokes. \n",
    "\n",
    "Format:\n",
    "> - A tab seperated file with 149 rows.\n",
    "> - The row number corresponds to the joke ID referred to in the ratings files below\n",
    "\n",
    "`jester_ratings.csv` contains the ratings data.\n",
    "\n",
    "Format:\n",
    "> - The data is formatted as a csv file representing a 1761439 by 3 matrix with rows containts rating of an user against joke in the format `UserID`, `ItemID` and `Rating`.\n",
    "> - The left-most column represents the UserID followed by ItemID(Joke) and Rating. There are a total of 59132 users and 140 jokes in this dataset.\n",
    "> - Some of the jokes don't have ratings, their ids are: 1, 2, 3, 4, 6, 9, 10, 11, 12, 14}.\n",
    "> - Each rating is from (-10.00 to +10.00).\n",
    "\n",
    "**Note that the ratings are real values ranging from -10.00 to +10.00. The jokes 1, 2, 3, 4, 6, 9, 10, 11, 12, 14 have been removed (i.e. they are never displayed or rated).***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Specify the files paths/names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/jester_jokes.tsv\n",
      "./datasets/jester_ratings.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "datasets_path = \"./datasets/\"\n",
    "jokes_dataset_path = os.path.join(datasets_path, \"jester_jokes.tsv\")\n",
    "ratings_dataset_path = os.path.join(datasets_path, \"jester_ratings.csv\")\n",
    "print(jokes_dataset_path)\n",
    "print(ratings_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\tA man visits the doctor. The doctor says, \"I have bad news for you. You have cancer and Alzheimer's disease\". The man replies, \"Well, thank God I don't have cancer!\"\n",
      "2:\tThis couple had an excellent relationship going until one day he came home from work to find his girlfriend packing. He asked her why she was leaving him and she told him that she had heard awful things about him. \"What could they possibly have said to make you move out?\" \"They told me that you were a pedophile.\" He replied, \"That's an awfully big word for a ten year old.\"\n",
      "3:\tQ. What's 200 feet long and has 4 teeth? A. The front row at a Willie Nelson concert.\n",
      "4:\tQ. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it.\n",
      "5:\tQ. What's O. J. Simpson's web address? A. Slash, slash, backslash, slash, slash, escape.\n",
      "6:\tBill and Hillary Clinton are on a trip back to Arkansas. They're almost out of gas, so Bill pulls into a service station on the outskirts of town. The attendant runs out of the station to serve them when Hillary realizes it's an old boyfriend from high school. She and the attendant chat as he gases up their car and cleans the windows. Then they all say goodbye. As Bill pulls the car onto the road, he turns to Hillary and says, \"Now aren't you glad you married me and not him? You could've been the wife of a grease monkey!\" To which Hillary replied, \"No, Bill. If I would have married him, you'd be pumping gas and he would be the President!\"\n",
      "7:\tHow many feminists does it take to screw in a light bulb? That's not funny.\n",
      "8:\tQ. Did you hear about the dyslexic devil worshiper? A. He sold his soul to Santa.\n",
      "9:\tA country guy goes into a city bar that has a dress code, and the maitre d' demands he wear a tie. Discouraged, the guy goes to his car to sulk when inspiration strikes: He's got jumper cables in the trunk! So he wraps them around his neck, sort of like a string tie (a bulky string tie to be sure) and returns to the bar. The maitre d' is reluctant, but says to the guy, \"Okay, you're a pretty resourceful fellow, you can come in... but just don't start anything!\"\n",
      "10:\tTwo cannibals are eating a clown. One turns to the other and says: \"Does this taste funny to you?\"\n"
     ]
    }
   ],
   "source": [
    "# Print first few rows from jokes and ratings datasets.\n",
    "!head ./datasets/jester_jokes.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserID,ItemID,Rating\n",
      "1,5,0.219\n",
      "1,7,-9.281\n",
      "1,8,-9.281\n",
      "1,13,-6.7810000000000015\n",
      "1,15,0.875\n",
      "1,16,-9.656\n",
      "1,17,-9.031\n",
      "1,18,-7.4689999999999985\n",
      "1,19,-8.719\n"
     ]
    }
   ],
   "source": [
    "!head ./datasets/jester_ratings.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Read the jokes dataset.\n",
    "\n",
    "this dataset is `tab` delimited and has two columns, `Joke`/`ItemID` and `Joke`.\n",
    "\n",
    "Load data from jokes dataset (`jokes_dataset_path`) into the dataframe `jokes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ItemID                                               Joke\n",
      "0     1:  A man visits the doctor. The doctor says, \"I h...\n",
      "1     2:  This couple had an excellent relationship goin...\n",
      "2     3:  Q. What's 200 feet long and has 4 teeth? A. Th...\n",
      "3     4:  Q. What's the difference between a man and a t...\n",
      "4     5:  Q. What's O. J. Simpson's web address? A. Slas...\n",
      "    ItemID                                               Joke\n",
      "144   145:  A blonde, brunette, and a red head are all lin...\n",
      "145   146:  America: 8:00 - Welcome to work! 12:00 - Lunch...\n",
      "146   147:  It was the day of the big sale. Rumors of the ...\n",
      "147   148:  Recently a teacher, a garbage collector, and a...\n",
      "148   149:  A little girl asked her father, \"Daddy? Do all...\n"
     ]
    }
   ],
   "source": [
    "#read the jokes Dataset\n",
    "jokes = \n",
    "\n",
    "# print first 5 rows.\n",
    "print(jokes.head())\n",
    "\n",
    "# print last 5 rows.\n",
    "print(jokes.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions of the jokes dataframe\n",
    "jokes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Read the ratings dataset.\n",
    "\n",
    "this dataset is `comma` delimited and has three columns, `UserId`, `ItemID` and `Rating`.\n",
    "\n",
    "Load data from ratings dataset (`ratings_dataset_path`) into the dataframe `ratings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  ItemID  Rating\n",
      "0       1       5   0.219\n",
      "1       1       7  -9.281\n",
      "2       1       8  -9.281\n",
      "3       1      13  -6.781\n",
      "4       1      15   0.875\n",
      "         UserID  ItemID  Rating\n",
      "1761434   63978      57  -8.531\n",
      "1761435   63978      24  -9.062\n",
      "1761436   63978     124  -9.031\n",
      "1761437   63978      58  -8.656\n",
      "1761438   63978      44  -8.438\n"
     ]
    }
   ],
   "source": [
    "#Read the Ratings Dataset\n",
    "ratings = \n",
    "# print first 5 rows.\n",
    "print(ratings.head())\n",
    "\n",
    "# print last 5 rows.\n",
    "print(ratings.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1761439, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions of the ratings dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique Items (JokeId) in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Convert the dataframes into surprise objects\n",
    "\n",
    "> - Surprise algorithms do not run on Pandas dataframe. \n",
    "- They require us to define the data format using a Reader Function and parse the data into a Surprise Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let us get familiar with the Reader and Dataset API in Surprise.\n",
    "\n",
    "To use Surprise, you should first know some of the basic modules and classes available in it:\n",
    "\n",
    "The Dataset module is used to load data from files, Pandas dataframes, or even built-in datasets available for experimentation. \n",
    "<br>(`movielens-100k`, `movielens-1m`, `Jester` are the built-in datasets in Surprise.) \n",
    "\n",
    "To load a dataset, some of the available methods are:\n",
    "> - Dataset.load_builtin()\n",
    "> - Dataset.load_from_file()\n",
    "> - Dataset.load_from_df()\n",
    "\n",
    "The Reader class is used to parse a file containing ratings. \n",
    "<br>The default format in which it accepts data is that each rating is stored in a separate line in the order user item rating. \n",
    "<br>This order and the separator can be configured using parameters:\n",
    "> - **line_format** is a string that stores the order of the data with field names separated by a space, as in \"item user rating\".\n",
    "> - **sep** is used to specify separator between fields, such as ','.\n",
    "> - **rating_scale** is used to specify the rating scale. The default is (1, 5).\n",
    "> - **skip_lines** is used to indicate the number of lines to skip at the beginning of the file. The default is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Defining the parser to read the data into surprise dataframe.</b>\n",
    "<b><br>The parser requires the scale of ratings, and the columns, to be mentioned using rating_scale and line_format.\n",
    "</b>\n",
    "\n",
    "**Limit to first 1000 users, to avoid the memory error.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Limit to 1000 users only - To avoid memory error.\n",
    "no_of_users = 1000\n",
    "\n",
    "reader = Reader(line_format=\"user item rating\", rating_scale = (-10, 10))\n",
    "jokes_data = Dataset.load_from_df(ratings[ratings.UserID < no_of_users], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.dataset.DatasetAutoFolds object at 0x7f9ac92e1b10>\n",
      "<class 'surprise.dataset.DatasetAutoFolds'>\n"
     ]
    }
   ],
   "source": [
    "# Verify the jokes_data object, This is a surprise object.\n",
    "print(jokes_data)\n",
    "print(type(jokes_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 5, 0.219, None),\n",
       " (1, 7, -9.281, None),\n",
       " (1, 8, -9.281, None),\n",
       " (1, 13, -6.7810000000000015, None),\n",
       " (1, 15, 0.875, None),\n",
       " (1, 16, -9.656, None),\n",
       " (1, 17, -9.031, None),\n",
       " (1, 18, -7.4689999999999985, None),\n",
       " (1, 19, -8.719, None),\n",
       " (1, 20, -9.156, None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify first 10 ratings from the raw_ratings attribute on surprise object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This returns a Surprise Dataset object which can be simply used to run algorithms. \n",
    "\n",
    "This means we don't have to explicitly convert the data into a user-item matrix.\n",
    "\n",
    "Let us see what we mean by converting into a user-item matrix. \n",
    "Our data has 3 columns - userId, itemId, Rating. We can use pivot_table to spread this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ItemID</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.219</td>\n",
       "      <td>-9.281</td>\n",
       "      <td>-9.281</td>\n",
       "      <td>-6.781</td>\n",
       "      <td>0.875</td>\n",
       "      <td>-9.656</td>\n",
       "      <td>-9.031</td>\n",
       "      <td>-7.469</td>\n",
       "      <td>-8.719</td>\n",
       "      <td>-9.156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.688</td>\n",
       "      <td>9.938</td>\n",
       "      <td>9.531</td>\n",
       "      <td>9.938</td>\n",
       "      <td>0.406</td>\n",
       "      <td>3.719</td>\n",
       "      <td>9.656</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-9.562</td>\n",
       "      <td>-9.125</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.844</td>\n",
       "      <td>-9.844</td>\n",
       "      <td>-7.219</td>\n",
       "      <td>-2.031</td>\n",
       "      <td>-9.938</td>\n",
       "      <td>-9.969</td>\n",
       "      <td>-9.875</td>\n",
       "      <td>-9.812</td>\n",
       "      <td>-9.781</td>\n",
       "      <td>-6.844</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.812</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>-4.906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.906</td>\n",
       "      <td>4.750</td>\n",
       "      <td>-5.906</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-4.031</td>\n",
       "      <td>3.875</td>\n",
       "      <td>6.219</td>\n",
       "      <td>5.656</td>\n",
       "      <td>6.094</td>\n",
       "      <td>5.406</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ItemID    5      7      8      13     15     16     17     18     19     20   \\\n",
       "UserID                                                                         \n",
       "1       0.219 -9.281 -9.281 -6.781  0.875 -9.656 -9.031 -7.469 -8.719 -9.156   \n",
       "2      -9.688  9.938  9.531  9.938  0.406  3.719  9.656 -2.688 -9.562 -9.125   \n",
       "3      -9.844 -9.844 -7.219 -2.031 -9.938 -9.969 -9.875 -9.812 -9.781 -6.844   \n",
       "4      -5.812 -4.500 -4.906    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "5       6.906  4.750 -5.906 -0.406 -4.031  3.875  6.219  5.656  6.094  5.406   \n",
       "\n",
       "ItemID  ...  141  142  143  144  145  146  147  148  149  150  \n",
       "UserID  ...                                                    \n",
       "1       ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2       ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3       ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4       ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "5       ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit to 1000 users only\n",
    "# Convert UserID into rows.\n",
    "# Convert ItemID into columns.\n",
    "# Convert Rating to the cell value.\n",
    "df1 = ratings[ratings.UserID < no_of_users].pivot_table(index = ['UserID'],\n",
    "                          columns = ['ItemID'],\n",
    "                          values = 'Rating')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(905, 140)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions of the above dataframe.\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_29",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## collaborative filtering.\n",
    "\n",
    "**Once the data is loaded we can build model on it.**\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "The scope of our learning is <b>Collaborative Filtering</b>. There are two techniques in CF.\n",
    "\n",
    "- <b>User Based</b> : If user u like item j, then recommend item k which was liked by other users who are similar to user u.\n",
    "- <b>Item based</b> : If user u like item j, then recommend item k which is similar to item j.\n",
    "\n",
    "</div>\n",
    "\n",
    "**Steps Involved in Collaborative Filtering**\n",
    "\n",
    "To build a system that can automatically recommend items to users based on the preferences of other users, the first step is to find similar users or items. The second step is to predict the ratings of the items that are not yet rated by a user. So, you will need the answers to these questions:\n",
    "\n",
    "    - How do you determine which users or items are similar to one another?\n",
    "    - Given that you know which users are similar, how do you determine the rating that a user would give to an item based on the ratings of similar users?\n",
    "    - How do you measure the accuracy of the ratings you calculate?\n",
    "    \n",
    "The first two questions don’t have single answers. Collaborative filtering is a family of algorithms where there are multiple ways to find similar users or items and multiple ways to calculate rating based on ratings of similar users. Depending on the choices you make, you end up with a type of collaborative filtering approach. \n",
    "\n",
    "The third question for how to measure the accuracy of your predictions also has multiple answers, which include error calculation techniques that can be used in many places and not just recommenders based on collaborative filtering.\n",
    "\n",
    "One of the approaches to measure the accuracy of your result is the Root Mean Square Error (RMSE), in which you predict ratings for a test dataset of user-item pairs whose rating values are already known. The difference between the known value and the predicted value would be the error. Square all the error values for the test set, find the average (or mean), and then take the square root of that average to get the RMSE.\n",
    "\n",
    "Another metric to measure the accuracy is Mean Absolute Error (MAE), in which you find the magnitude of error by finding its absolute value and then taking the average of all error values.\n",
    "\n",
    "### Different types of algorithms in the family of collaborative filtering.\n",
    "\n",
    "#### Memory Based\n",
    "\n",
    "The first category includes algorithms that are memory based, in which statistical techniques are applied to the entire dataset to calculate the predictions.\n",
    "\n",
    "To find the rating R that a user U would give to an item I, the approach includes:\n",
    "> - Finding users similar to U who have rated the item I\n",
    "- Calculating the rating R based the ratings of users found in the previous step\n",
    "\n",
    "**How to Find Similar Users on the Basis of Ratings**\n",
    "\n",
    "To understand the concept of similarity, let’s create a simple dataset first.\n",
    "\n",
    "The data includes four users A, B, C, and D, who have rated two movies. The ratings are stored in lists, and each list contains two numbers indicating the rating of each movie:\n",
    "\n",
    "> - Ratings by A are [1.0, 2.0].\n",
    "- Ratings by B are [2.0, 4.0].\n",
    "- Ratings by C are [2.5, 4.0].\n",
    "- Ratings by D are [4.5, 5.0].\n",
    "\n",
    "Plot the ratings of two movies given by the users on a graph and look for a pattern. \n",
    "\n",
    "The graph looks like this:\n",
    "![vectors](./images/sim-vectors.png)\n",
    "\n",
    "In the graph above, each point represents a user and is plotted against the ratings they gave to two movies.\n",
    "\n",
    "Looking at the distance between the points seems to be a good way to estimate similarity,  right? \n",
    "\n",
    "You can find the distance using the formula for Euclidean distance between two points. \n",
    "\n",
    "You can use the function available in scipy as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Data points\n",
    "A = [1.0, 2.0]\n",
    "B = [2.0, 4.0]\n",
    "C = [2.5, 4.0]\n",
    "D = [4.5, 5.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Find the distance between A, B and D to C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distances\n",
      "===================\n",
      "C-A :  2.5\n",
      "C-B :  0.5\n",
      "C-D :  2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "print(\"Euclidean Distances\")\n",
    "print(\"===================\")\n",
    "print(\"C-A : \", spatial.distance.euclidean(C, A))\n",
    "print(\"C-B : \", spatial.distance.euclidean(C, B))\n",
    "print(\"C-D : \", spatial.distance.euclidean(C, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_33",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can see that user C is closest to B even by looking at the graph. \n",
    "\n",
    "But **out of A and D only, who is C closer to?**\n",
    "\n",
    "You could say C is closer to D in terms of distance. \n",
    "But looking at the rankings, it would seem that the choices of C would align with that of A more than D because both A and C like the second movie almost twice as much as they like the first movie, but D likes both of the movies equally.\n",
    "\n",
    "So, what can you use to identify such patterns that Euclidean distance cannot? \n",
    "\n",
    "Can the angle between the lines joining the points to the origin be used to make a decision? \n",
    "\n",
    "You can take a look at the angle between the lines joining the origin of the graph to the respective points as shown:\n",
    "\n",
    "![cosine_distance](./images/sim-cosine.png)\n",
    "\n",
    "The graph shows four lines joining each point to the origin. The lines for A and B are coincident, making the angle between them zero.\n",
    "\n",
    "You can consider that, if the angle between the lines is increased, then the similarity decreases, and if the angle is zero, then the users are very similar.\n",
    "\n",
    "To calculate similarity using angle, you need a function that returns a higher similarity or smaller distance for a lower angle and a lower similarity or larger distance for a higher angle. \n",
    "\n",
    "**The cosine of an angle is a function that decreases from 1 to -1 as the angle increases from 0 to 180.**\n",
    "\n",
    "You can use the cosine of the angle to find the similarity between two users. \n",
    "\n",
    "The higher the angle, the lower will be the cosine and thus, the lower will be the similarity of the users. You can also inverse the value of the cosine of the angle to get the cosine distance between the users by subtracting it from 1.\n",
    "\n",
    "scipy has a function that calculates the cosine distance of vectors. It returns a higher value for higher angle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_34",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Distances\n",
      "================\n",
      "C-A :  0.004504527406047898\n",
      "C-B :  0.004504527406047898\n",
      "C-D :  0.015137225946083022\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "print(\"Cosine Distances\")\n",
    "print(\"================\")\n",
    "print(\"C-A : \", spatial.distance.cosine(C, A))\n",
    "print(\"C-B : \", spatial.distance.cosine(C, B))\n",
    "print(\"C-D : \", spatial.distance.cosine(C, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The lower angle between the vectors of C and A gives a lower cosine distance value. If you want to rank user similarities in this way, use cosine distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Algorithms Based on K-Nearest Neighbours (k-NN)\n",
    "\n",
    "For the memory-based approaches discussed above, the algorithm that would fit the bill is Centered k-NN because the algorithm is very close to the centered cosine similarity formula explained above. It is available in Surprise as KNNWithMeans.\n",
    "\n",
    "To find the similarity, you simply have to configure the function by passing a dictionary as an argument to the recommender function. The dictionary should have the required keys, such as the following:\n",
    "\n",
    "> - **name** contains the similarity metric to use. Options are cosine, msd, pearson, or pearson_baseline. The default is msd.\n",
    "- **user_based** is a boolean that tells whether the approach will be user-based or item-based. The default is True, which means the user-based approach will be used.\n",
    "- **min_support** is the minimum number of common items needed between users to consider them for similarity. For the item-based approach, this corresponds to the minimum number of common users for two items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "similarity_parameters = {\n",
    "    'name' : 'cosine',\n",
    "    'user_based': True,\n",
    "    'min_support' : 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**How many neighbours should we consider?**\n",
    "\n",
    "This is a hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans\n",
    "\n",
    "KNN_Algo = KNNWithMeans(k=3, sim_options = similarity_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Training using cross validation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    5.1991  5.3297  5.3089  5.2390  5.3423  5.2838  0.0554  \n",
      "MAE (testset)     3.9965  4.0826  4.0945  4.0168  4.0944  4.0570  0.0418  \n",
      "Fit time          0.51    0.53    0.52    0.52    0.52    0.52    0.00    \n",
      "Test time         1.07    1.07    1.06    1.08    1.10    1.08    0.01    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([5.19909587, 5.32971846, 5.30887175, 5.23897823, 5.34225415]),\n",
       " 'test_mae': array([3.99654182, 4.082614  , 4.0944657 , 4.01678773, 4.09435684]),\n",
       " 'fit_time': (0.5107889175415039,\n",
       "  0.5251379013061523,\n",
       "  0.5161430835723877,\n",
       "  0.5207030773162842,\n",
       "  0.5194323062896729),\n",
       " 'test_time': (1.071791172027588,\n",
       "  1.0700039863586426,\n",
       "  1.0624070167541504,\n",
       "  1.0799298286437988,\n",
       "  1.0991268157958984)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "cross_validate(KNN_Algo, \n",
    "               jokes_data, \n",
    "               measures=['RMSE', 'MAE'], \n",
    "               cv=5, \n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Training the model on complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x7f9ac3d9d210>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use full data for training\n",
    "\n",
    "trainset = jokes_data.build_full_trainset()\n",
    "\n",
    "KNN_Algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Filter the instances which can be used for predictions\n",
    "\n",
    "**build_anti_testset**: Return a list of ratings that can be used as a testset in the test() method.\n",
    "\n",
    "The ratings are all the ratings that are not in the trainset, i.e. all the ratings 𝑟𝑢𝑖 where the user 𝑢 is known, the item 𝑖 is known, but the rating 𝑟𝑢𝑖 is not in the trainset. As 𝑟𝑢𝑖 is unknown, it is either replaced by the fill value or assumed to be equal to the mean of all ratings global_mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Getting data points where predictions can be made\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_47",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Making Predictions\n",
    "\n",
    "Surprise provide a [Prediction](https://surprise.readthedocs.io/en/stable/predictions_module.html#surprise.prediction_algorithms.predictions.Prediction) object which is a named tuple with the following details.\n",
    "\n",
    "A named tuple for storing the results of a prediction.\n",
    "\n",
    "It’s wrapped in a class, but only for documentation and printing purposes.\n",
    "Parameters:\t\n",
    "\n",
    "> - uid – The (raw) user id. See this note.\n",
    "> - iid – The (raw) item id. See this note. \n",
    "> - r_ui (float) – The true rating 𝑟𝑢𝑖\n",
    "> - est (float) – The estimated rating 𝑟̂ 𝑢𝑖\n",
    "> - details (dict) – Stores additional details about the prediction that might be useful for later analysis.\n",
    "> - actual_k : number of neighours used to calculate the rating (provided while defining the algo)\n",
    "> - was_impossible : Exception raised when a prediction is impossible. When raised, the estimation 𝑟̂ 𝑢𝑖 is set to the global mean of all ratings 𝜇."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "predictions = KNN_Algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1, iid=28, r_ui=1.3216032090880538, est=2.6352948949376396, details={'actual_k': 3, 'was_impossible': False}),\n",
       " Prediction(uid=1, iid=30, r_ui=1.3216032090880538, est=1.1482308258829255, details={'actual_k': 3, 'was_impossible': False}),\n",
       " Prediction(uid=1, iid=48, r_ui=1.3216032090880538, est=4.834358515828926, details={'actual_k': 3, 'was_impossible': False}),\n",
       " Prediction(uid=1, iid=33, r_ui=1.3216032090880538, est=-2.429074772927871, details={'actual_k': 3, 'was_impossible': False})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify few predictions\n",
    "predictions[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Function to calculate top 10 predictions for each user\n",
    "\n",
    "Followint is the code that finds top 10 recommendations/suggestions on jokes for a user. \n",
    "\n",
    "These are the joke Ids the user hasn't rated yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  [(145, 9.220575376144698),\n",
       "   (56, 7.455773317925031),\n",
       "   (137, 6.6595656010858795),\n",
       "   (136, 6.609596458285943),\n",
       "   (147, 6.542035610113534),\n",
       "   (122, 6.039233244935499),\n",
       "   (114, 5.874395361657554),\n",
       "   (139, 5.731022402892997),\n",
       "   (78, 5.5808023924561665),\n",
       "   (113, 5.372598101303155)]),\n",
       " (2,\n",
       "  [(121, 8.250787765350049),\n",
       "   (126, 7.941681006504824),\n",
       "   (130, 7.836405825603136),\n",
       "   (122, 7.335861745593466),\n",
       "   (105, 7.143615137560851),\n",
       "   (52, 7.008628702709968),\n",
       "   (98, 6.950833379616794),\n",
       "   (116, 6.788894011795453),\n",
       "   (124, 6.656663139292329),\n",
       "   (146, 6.593037144129996)]),\n",
       " (3,\n",
       "  [(138, 3.137880796773408),\n",
       "   (139, 2.9304844258730123),\n",
       "   (110, 1.9402686101904942),\n",
       "   (35, 0.7841973859761717),\n",
       "   (36, -0.35630174577875007),\n",
       "   (72, -0.8699021947568584),\n",
       "   (114, -1.6131133145698158),\n",
       "   (142, -1.7084131601259251),\n",
       "   (76, -1.7554968221795617),\n",
       "   (123, -2.0684151247102642)]),\n",
       " (4,\n",
       "  [(106, 0.8182247684630441),\n",
       "   (108, 0.5531405187544545),\n",
       "   (69, 0.03836103361967691),\n",
       "   (63, -0.12210892996318101),\n",
       "   (93, -0.13257203521195926),\n",
       "   (116, -0.1487222575927012),\n",
       "   (32, -0.8719278672590915),\n",
       "   (48, -0.9064993849824896),\n",
       "   (40, -0.9790341585375604),\n",
       "   (21, -0.9923627126864485)]),\n",
       " (5,\n",
       "  [(143, 6.03996684662836),\n",
       "   (117, 5.365127169981138),\n",
       "   (149, 5.060266207338907),\n",
       "   (114, 4.851786154157191),\n",
       "   (134, 4.737463748530815),\n",
       "   (145, 4.591653738321874),\n",
       "   (71, 4.43305310680793),\n",
       "   (140, 4.43138570241485),\n",
       "   (126, 4.371676468518908),\n",
       "   (148, 4.359140319145581)]),\n",
       " (6,\n",
       "  [(102, 4.324864020773914),\n",
       "   (113, 3.926063880264823),\n",
       "   (76, 3.9122145510312913),\n",
       "   (130, 3.614266887318993),\n",
       "   (127, 3.105772638110537),\n",
       "   (112, 2.7809144408524853),\n",
       "   (117, 2.7686154576786706),\n",
       "   (106, 2.6476212406530246),\n",
       "   (88, 2.460336805713256),\n",
       "   (125, 1.9198624806976667)]),\n",
       " (7,\n",
       "  [(127, 5.970389788713015),\n",
       "   (77, 5.701845936476433),\n",
       "   (43, 4.96013690540111),\n",
       "   (116, 4.789706236070393),\n",
       "   (115, 4.373403399405531),\n",
       "   (105, 4.160450288514077),\n",
       "   (108, 4.1083088924110065),\n",
       "   (118, 3.969849240505355),\n",
       "   (25, 3.939655542852896),\n",
       "   (117, 3.909744368398047)]),\n",
       " (8,\n",
       "  [(143, 10),\n",
       "   (131, 9.552827835119103),\n",
       "   (132, 8.290889299856019),\n",
       "   (134, 7.7274134176179325),\n",
       "   (114, 7.055554308431813),\n",
       "   (128, 6.522961739645508),\n",
       "   (147, 6.230621640767668),\n",
       "   (142, 5.044332721369987),\n",
       "   (118, 4.298029493504767),\n",
       "   (138, 4.116597670279865)]),\n",
       " (9,\n",
       "  [(27, 9.243157511211976),\n",
       "   (116, 8.41186017200208),\n",
       "   (40, 8.314960899632865),\n",
       "   (66, 8.285039704248728),\n",
       "   (104, 8.082261125798752),\n",
       "   (148, 7.970163143381578),\n",
       "   (60, 7.819481526385603),\n",
       "   (81, 7.598545634548305),\n",
       "   (31, 7.416104198467744),\n",
       "   (43, 7.411303713706776)]),\n",
       " (10,\n",
       "  [(135, 6.580922710370215),\n",
       "   (113, 6.076086567103865),\n",
       "   (127, 6.021392729571688),\n",
       "   (148, 5.826361733387863),\n",
       "   (138, 5.535545915578653),\n",
       "   (150, 5.41294197375075),\n",
       "   (140, 5.198365238437307),\n",
       "   (149, 5.1839307449946315),\n",
       "   (114, 5.148145293985158),\n",
       "   (112, 5.096322957286215)])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching top 10 predictions for each user\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "top_n = get_top_n(predictions, n=10)\n",
    "take(10, top_n.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "####  Top Predictions Matrix\n",
    "\n",
    "Create a matrix of top-10 recommendations/suggestions for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [145, 56, 137, 136, 147, 122, 114, 139, 78, 113]\n",
      "2 [121, 126, 130, 122, 105, 52, 98, 116, 124, 146]\n",
      "3 [138, 139, 110, 35, 36, 72, 114, 142, 76, 123]\n",
      "4 [106, 108, 69, 63, 93, 116, 32, 48, 40, 21]\n",
      "5 [143, 117, 149, 114, 134, 145, 71, 140, 126, 148]\n",
      "6 [102, 113, 76, 130, 127, 112, 117, 106, 88, 125]\n",
      "7 [127, 77, 43, 116, 115, 105, 108, 118, 25, 117]\n",
      "8 [143, 131, 132, 134, 114, 128, 147, 142, 118, 138]\n",
      "9 [27, 116, 40, 66, 104, 148, 60, 81, 31, 43]\n",
      "10 [135, 113, 127, 148, 138, 150, 140, 149, 114, 112]\n"
     ]
    }
   ],
   "source": [
    "# Printing top predictions\n",
    "for uid, user_ratings in take(10,top_n.items()):\n",
    "    print(uid, [iid for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ItemID                                                 117:\n",
       "Joke      A man joins a big corporate empire as a traine...\n",
       "Name: 116, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a joke text\n",
    "jokes.iloc[116]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Recommended jokes for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For User 1\n",
      "145\n",
      "A blonde, brunette, and a red head are all lined up to be shot to death by a firing squad. The brunette shouts, \"Tornado!\" and the riflemen turn around to see the tornado. It isn't there, and the brunette uses that time to escape. The red head yells, \"Lightning!\" and the riflemen again turn to see the disaster, yet there is no disaster and the red head escapes. The blonde yells, \"Fire!\" The riflemen do.\n",
      "56\n",
      "A man and Cindy Crawford get stranded on a desert island. After a couple of days they fall in love and start sleeping together. Time passes and the man seems frustrated. Cindy asks if there is anything she can do, and he says there is one thing: \"Could you put on this baseball cap and go to the other side of the island and answer me when I call you Bob?\" She agrees. The next day he is walking on the other side of the island and runs into her. He says, \"Hi Bob!\" She says, \"Hello, what's up?\" He replies, \"Bob, you won't believe it: I've been sleeping with Cindy Crawford for the past two weeks!\"\n",
      "137\n",
      "Deep within a forest, a little turtle began to climb a tree. After hours of effort, he reached the top, jumped into the air waving his front legs and crashed to the ground. After recovering, he slowly climbed the tree again, jumped, and fell to the ground. The turtle tried again and again, while a couple of birds sitting on a branch watched his sad efforts. Finally, the female bird turned to her mate. \"Dear,\" she chirped, \"I think it's time to tell him he's adopted.\"\n",
      "136\n",
      "A man went to apply for a job. After filling out all of his applications, he waited anxiously for the outcome. The employer read all his applications and said, \"We have an opening for people like you.\" \"Oh, great,\" he said. \"What is it?\" \"It's called the door!\"\n",
      "147\n",
      "It was the day of the big sale. Rumors of the sale (and some advertising in the local paper) were the main reason for the long line that formed by 8:30, the store's opening time, in front of the store. A small man pushed his way to the front of the line, only to be pushed back, amid loud and colorful curses. On the man's second attempt, he was punched square in the jaw, and knocked around a bit, and then thrown to the end of the line again. As he got up the second time, he said to the person at the end of the line... \"That does it! If they hit me one more time, I won't open the store!\"\n",
      "122\n",
      "An astronomer, a physicist and a mathematician (it is said) were holidaying in Scotland. Glancing from a train window, they observed a black sheep in the middle of a field. \"How interesting,\" observed the astronomer, \"All Scottish sheep are black!\" To which the physicist responded, \"No, no! Some Scottish sheep are black!\" The mathematician gazed heavenward in supplication, and then intoned, \"In Scotland there exists at least one field, containing at least one sheep, at least one side of which is black.\"\n",
      "114\n",
      "Sherlock Holmes and Dr. Watson go on a camping trip, set up their tent, and fall asleep. Some hours later, Holmes wakes his faithful friend. \"Watson, look up at the sky and tell me what you see.\" Watson replies, \"I see millions of stars.\" \"What does that tell you?\" Watson ponders for a minute. \"Astronomically speaking, it tells me that there are millions of galaxies and potentially billions of planets. Astrologically, it tells me that Saturn is in Leo. Timewise, it appears to be approximately a quarter past three. Theologically, it's evident the Lord is all-powerful and we are small and insignificant. Meteorologically, it seems we will have a beautiful day tomorrow. What does it tell you?\" Holmes is silent for a moment, then speaks. \"Watson, you idiot, someone has stolen our tent.\"\n",
      "139\n",
      "In a Veteran's Day speech, President Bush vowed, \"We will finish the mission. Period.\" Afterwards, he was advised that he doesn't have to read the punctuation marks.\n",
      "78\n",
      "Q: What's the difference between the government and the Mafia? A: One of them is organized.\n",
      "113\n",
      "The new employee stood before the paper shredder looking confused. \"Need some help?\" a secretary asked. \"Yes,\" he replied. \"How does this thing work?\" \"Simple,\" she said, taking the fat report from his hand and feeding it into the shredder. \"Thanks, but where do the copies come out?\"\n",
      "For User 2\n",
      "121\n",
      "A drunk staggers into a Catholic Church, enters a confessional booth, sits down, but says nothing. The Priest coughs a few times to get his attention but the drunk just sits there. Finally, the Priest pounds three times on the wall. The drunk mumbles, \"Ain't no use knockin, there's no paper on this side either.\"\n",
      "126\n",
      "A Briton, a Frenchman and a Russian are viewing a painting of Adam and Eve frolicking in the Garden of Eden. \"Look at their reserve, their calm,\" muses the Brit. \"They must be British.\" \"Nonsense,\" the Frenchman disagrees. \"They're naked, and so beautiful. Clearly, they are French.\" \"No way! They have no clothes and no shelter,\" the Russian points out, \"They have only an apple to eat, and they are being told they live in a paradise. Obviously, they are Russian.\"\n",
      "130\n",
      "An old man goes to the doctor for his yearly physical, his wife tagging along. When the doctor enters the examination room, he tells the old man, \"I need a urine sample, a stool sample and a sperm sample.\" The old man, being hard of hearing, looks at his wife and yells: \"WHAT? What did he say? What's he want?\" His wife yells back, \"He needs your underwear.\"\n",
      "122\n",
      "An astronomer, a physicist and a mathematician (it is said) were holidaying in Scotland. Glancing from a train window, they observed a black sheep in the middle of a field. \"How interesting,\" observed the astronomer, \"All Scottish sheep are black!\" To which the physicist responded, \"No, no! Some Scottish sheep are black!\" The mathematician gazed heavenward in supplication, and then intoned, \"In Scotland there exists at least one field, containing at least one sheep, at least one side of which is black.\"\n",
      "105\n",
      "A couple of hunters are out in the woods in the deep south when one of them falls to the ground. He doesn't seem to be breathing, and his eyes are rolled back in his head. The other guy whips out his cell phone and calls 911. He gasps to the operator, \"My friend is dead! What can I do?\" The operator, in a calm and soothing voice, says, \"Alright, take it easy. I can help. First, let's make sure he's dead.\" There is silence, and then a gun shot is heard. The hunter comes back on the line. \"Okay. Now what??\"\n",
      "52\n",
      "Q: What do Monica Lewinsky and Bob Dole have in common? A: They were both upset when Bill finished first.\n",
      "98\n",
      "Age and Womanhood 1. Between the ages of 13 and 18... She is like Africa, virgin and unexplored. 2. Between the ages of 19 and 35... She is like Asia, hot and exotic. 3. Between the ages of 36 and 45... She is like America, fully explored, breathtakingly beautiful, and free with her resources. 4. Between the ages of 46 and 56... She is like Europe, exhausted but still has points of interest. 5. After 56 she is like Australia... Everybody knows it's down there, but who gives a damn?\n",
      "116\n",
      "A man in a hot air balloon realized he was lost. He reduced altitude and spotted a woman below. He descended a bit more and shouted, \"Excuse me, can you help me? I promised a friend I would meet him an hour ago, but I don't know where I am.\" The woman below replied, \"You are in a hot air balloon hovering approximately 30 feet above the ground. You are between 40 and 41 degrees north latitude and between 59 and 60 degrees west longitude.\" \"You must be an engineer,\" said the balloonist. \"I am,\" replied the woman. \"How did you know?\" \"Well,\" answered the balloonist, \"everything you told me is technically correct, but I have no idea what to make of your information, and the fact is, I am still lost. Frankly, you've not been much help so far.\" The woman below responded, \"You must be in management.\" \"I am,\" replied the balloonist, \"but how did you know?\" \"Well,\" said the woman, \"you don't know where you are or where you are going. You have risen to where you are due to a large quantity of hot air. You made a promise that you have no idea how to keep, and you expect people beneath you to solve your problems. The fact is, you are in exactly the same position you were in before we met, but now, somehow, it's my fault!\"\n",
      "124\n",
      "Person 1: Hey, wanna hear a great knock-knock joke? Person 2: Sure, What is it? Person 1: Okay, you start. Person 2: Knock-knock. Person 1: Who's there? Person 2: ... Person 1: Hah!\n",
      "146\n",
      "America: 8:00 - Welcome to work! 12:00 - Lunch break 17:00 - The work day is over Japan: 8:00 - Are you already at work? 12:00 - Continue your work 17:00 - The work day is over 20:00 - Please finish your work Romania: 8:00 - Has anyone come to work? 12:00 - Did someone start working? 16:00 - Is anyone at work?\n",
      "For User 3\n",
      "138\n",
      "WASHINGTON (Reuters) - A tragic fire on Monday destroyed the personal library of President George W. Bush. Both of his books have been lost. Presidential spokesman Ari Fleischer said the president was devastated, as he had not finished coloring the second one.\n",
      "139\n",
      "In a Veteran's Day speech, President Bush vowed, \"We will finish the mission. Period.\" Afterwards, he was advised that he doesn't have to read the punctuation marks.\n",
      "110\n",
      "One day, a professor was giving a big test to his students. He handed out the tests and went back to his desk to wait. Once the test was over, the students all handed the tests back in. The professor noticed that one of the students had attached a $100 bill to his test with a note saying: \"A dollar per point.\" The next class the professor handed the tests back out. This student got back his test...and $64 change!\n",
      "35\n",
      "An explorer in the deepest Amazon suddenly finds himself surrounded by a bloodthirsty group of natives. Upon surveying the situation, he says quietly to himself, \"Oh God, I'm screwed.\" The sky darkens and a voice booms out, \"No, you are NOT screwed. Pick up that stone at your feet and bash in the head of the chief standing in front of you.\" So with the stone he bashes the life out of the chief. He stands above the lifeless body, breathing heavily and looking at 100 angry natives... The voice booms out again, \"Okay....NOW you're screwed.\"\n",
      "36\n",
      "A guy walks into a bar, orders a beer and says to the bartender, \"Hey, I got this great Polish Joke...\" The barkeep glares at him and says in a warning tone of voice: \"Before you go telling that joke you better know that I'm Polish, both bouncers are Polish and so are most of my customers.\" \"Okay,\" says the customer. \"I'll tell it very slowly.\"\n",
      "72\n",
      "On the first day of college, the Dean addressed the students, pointing out some of the rules: \"The female dormitory will be out-of-bounds for all male students and the male dormitory to the female students. Anybody caught breaking this rule will be finded $20 the first time.\" He continued, \"Anybody caught breaking this rule the second time will be fined $60. Being caught a third time will cost you a fine of $180. Are there any questions?\" At this point, a male student in the crowd inquired: \"How much for a season pass?\"\n",
      "114\n",
      "Sherlock Holmes and Dr. Watson go on a camping trip, set up their tent, and fall asleep. Some hours later, Holmes wakes his faithful friend. \"Watson, look up at the sky and tell me what you see.\" Watson replies, \"I see millions of stars.\" \"What does that tell you?\" Watson ponders for a minute. \"Astronomically speaking, it tells me that there are millions of galaxies and potentially billions of planets. Astrologically, it tells me that Saturn is in Leo. Timewise, it appears to be approximately a quarter past three. Theologically, it's evident the Lord is all-powerful and we are small and insignificant. Meteorologically, it seems we will have a beautiful day tomorrow. What does it tell you?\" Holmes is silent for a moment, then speaks. \"Watson, you idiot, someone has stolen our tent.\"\n",
      "142\n",
      "One day, three men went to a shrine to ask the Father for forgiveness. The first man went to the Father... First Man: \"Father, Father, I have sinned!\" Father: \"What have you done?\" First Man: \"I have lied!\" Father: \"Drink the holy water and you will be saved.\" And so the man drank the water and was \"saved.\" The second man went up to the Father... Second Man: \"Father, Father, I have sinned!\" Father: \"What have you done?\" Second Man: \"I have stolen from the jeweler's!\" Father: \"Drink the holy water and you will be saved.\" And so the second man drank the holy water and was \"saved.\" The third man went up to the Father... Third Man: \"Father, Father, I have sinned!\" Father: \"What have you done?\" Third Man: \"I peed in the holy water!\"\n",
      "76\n",
      "There once was a man and a woman that both got in a terrible car wreck. Both of their vehicles were completely destroyed, buy fortunately, no one was hurt. In thankfulness, the woman said to the man, \"We are both okay, so we should celebrate. I have a bottle of wine in my car: let's open it.\" So the woman got the bottle out of the car, and handed it to the man. The man took a really big drink, and handed the woman the bottle. The woman closed the bottle and put it down. The man asked, \"Aren't you going to take a drink?\" The woman cleverly replied, \"No, I think I'll just wait for the cops to get here.\"\n",
      "123\n",
      "When most people claim to be \"killing time\", it's only an expression. When Chuck Norris kills time, the minutes actually cease to exist.\n",
      "For User 4\n",
      "106\n",
      "An engineer dies and reports to the pearly gates. St. Peter checks his dossier and says, \"Ah, you''re an engineer--you're in the wrong place.\" So, the engineer reports to the gates of hell and is let in. Pretty soon, the engineer gets dissatisfied with the level of comfort in hell, and starts designing and building improvements. After awhile, they've got air conditioning, flush toilets and escalators, and the engineer is a pretty popular guy. One day, God calls Satan up on the telephone and says with a sneer, \"So, how's it going down there in hell?\" Satan replies, \"Hey, things are going great. We've got air conditioning, flush toilets and escalators, and there's no telling what this engineer is going to come up with next.\" God replies, \"What?? You've got an engineer? That's a mistake--he should never have gotten down there; send him up here.\" Satan says, \"No way.\" I like having an engineer on the staff, and I'm keeping him.\" God says, \"Send him back up here or I'll sue.\" Satan laughs uproariously and answers, \"Yeah, right. And just where are YOU going to get a lawyer?\"\n",
      "108\n",
      "A man approached a very beautiful woman in a large supermarket and asked, \"You know, I've lost my wife here in the supermarket. Can you talk to me for a couple of minutes?\" \"Why?\" \"Because every time I talk to a beautiful woman my wife appears out of nowhere.\"\n",
      "69\n",
      "This guy's wife asks, \"Honey, if I died would you remarry?\" and he replies, \"Well, after a considerable period of grieving, we all need companionship, so I guess I would.\" She then asks, \"If I died and you remarried, would she live in this house?\" and he replies, \"We've spent a lot of time and money getting this house just the way we want it. I'm not going to get rid of my house, so I guess she would.\" \"If I died and you remarried, and she lived in this house, would she sleep in our bed?\" and he says, \"That bed is brand new. We just paid two thousand dollars for it, and it's going to last a long time, so I guess she would.\" So she asks, \"If I died and you remarried, and she lived in this house, and slept in our bed, would she use my golf clubs?\" \"Oh no, she's left handed.\"\n",
      "63\n",
      "An engineer, a physicist and a mathematician are sleeping in a room. There is a fire in the room. The engineer wakes up, sees the fire, picks up the bucket of water and douses the fire and goes back to sleep. Again there is a fire in the room. This time, the physicist wakes up, notices the bucket, fills it with water, calculates the optimal trajectory and douses the fire in minimum amount of water and goes back to sleep. Again there is a fire. This time the mathematician wakes up. He looks at the fire, looks at the bucket and the water and exclaims, \"A solution exists!\" and goes back to sleep.\n",
      "93\n",
      "Reaching the end of a job interview, the human resources person asked a young engineer fresh out of Stanford, \"And what starting salary were you looking for?\" The engineer said, \"In the neighborhood of $125,000 a year, depending on the benefits package.\" The interviewer said, \"Well, what would you say to a package of 5-weeks vacation, 14 paid holidays, full medical and dental, company matching retirement fund to 50% of salary, and a company car leased every 2 years--say, a red Corvette?\" The engineer sat up straight and said, \"Wow! Are you kidding?\" And the interviewer replied, \"Yeah, but you started it.\"\n",
      "116\n",
      "A man in a hot air balloon realized he was lost. He reduced altitude and spotted a woman below. He descended a bit more and shouted, \"Excuse me, can you help me? I promised a friend I would meet him an hour ago, but I don't know where I am.\" The woman below replied, \"You are in a hot air balloon hovering approximately 30 feet above the ground. You are between 40 and 41 degrees north latitude and between 59 and 60 degrees west longitude.\" \"You must be an engineer,\" said the balloonist. \"I am,\" replied the woman. \"How did you know?\" \"Well,\" answered the balloonist, \"everything you told me is technically correct, but I have no idea what to make of your information, and the fact is, I am still lost. Frankly, you've not been much help so far.\" The woman below responded, \"You must be in management.\" \"I am,\" replied the balloonist, \"but how did you know?\" \"Well,\" said the woman, \"you don't know where you are or where you are going. You have risen to where you are due to a large quantity of hot air. You made a promise that you have no idea how to keep, and you expect people beneath you to solve your problems. The fact is, you are in exactly the same position you were in before we met, but now, somehow, it's my fault!\"\n",
      "32\n",
      "A man arrives at the gates of heaven. St. Peter asks, \"Religion?\" The man says, \"Methodist.\" St. Peter looks down his list, and says, \"Go to room 24, but be very quiet as you pass room 8.\" Another man arrives at the gates of heaven. \"Religion?\" \"Baptist.\" \"Go to room 18, but be very quiet as you pass room 8.\" A third man arrives at the gates. \"Religion?\" \"Jewish.\" \"Go to room 11, but be very quiet as you pass room 8.\" The man says, \"I can understand there being different rooms for different religions, but why must I be quiet when I pass room 8?\" St. Peter tells him, \"Well, the Catholics are in room 8, and they think they're the only ones here.\"\n",
      "48\n",
      "The graduate with a Science degree asks, \"Why does it work?\" The graduate with an Engineering degree asks, \"How does it work?\" The graduate with an Accounting degree Asks, \"How much will it cost?\" The graduate with a Liberal Arts degree asks, \"Do you want fries with that?\"\n",
      "40\n",
      "How many Irishmen does it take to change a lightbulb? Two. One to hold the lightbulb and the other to drink until the room spins.\n",
      "21\n",
      "What's the difference between a used tire and 365 used condoms? One's a Goodyear, the other's a great year.\n",
      "For User 5\n",
      "143\n",
      "A preist, a 12-year-old kid, and the smartest guy in the world are on a plane. The pilot screams, \"The plane is going down! You have to jump!\" He then grabs a parachute and jumps off, leaving only two more parachutes on the plane. The smartest guy in the world says, \"I have to go. I mean, I'm the smartest guy in the world!\" He grabs a parachute, and jumps. The priest then looks at the 12-year-old kid, and says, \"Go, my son. You have a long life to live.\" The kid calmly responds: \"Dude, chill. We'll be fine. The 'smartest guy in the world' took my backpack.\"\n",
      "117\n",
      "A man joins a big corporate empire as a trainee. On his very first day of work, he dials the pantry and shouts into the phone: \"Get me a coffee, quickly!\" The voice from the other side responds, \"You fool, you've dialed the wrong extension! Do you know who you're talking to, dumbo?\" \"No,\" replied the trainee. \"It's the CEO of the company, you fool!\" The trainee shouts back, \"And do YOU know who YOU are talking to, you fool?!\" \"No.\" replied the CEO indignantly. \"Good!\" replied the trainee, and puts down the phone.\n",
      "149\n",
      "A little girl asked her father, \"Daddy? Do all fairy tales begin with 'Once Upon a Time'?\" He replied, \"No, there is a whole series of fairy tales that begin with 'If elected I promise'.\"\n",
      "114\n",
      "Sherlock Holmes and Dr. Watson go on a camping trip, set up their tent, and fall asleep. Some hours later, Holmes wakes his faithful friend. \"Watson, look up at the sky and tell me what you see.\" Watson replies, \"I see millions of stars.\" \"What does that tell you?\" Watson ponders for a minute. \"Astronomically speaking, it tells me that there are millions of galaxies and potentially billions of planets. Astrologically, it tells me that Saturn is in Leo. Timewise, it appears to be approximately a quarter past three. Theologically, it's evident the Lord is all-powerful and we are small and insignificant. Meteorologically, it seems we will have a beautiful day tomorrow. What does it tell you?\" Holmes is silent for a moment, then speaks. \"Watson, you idiot, someone has stolen our tent.\"\n",
      "134\n",
      "An artist asked the gallery owner if there had been any interest in his paintings currently on display. \"I've got good news and bad news,\" the owner replied. \"The good news is that a gentleman inquired about your work and wondered if it would appreciate in value after your death. When I told him it would, he bought all fifteen of your paintings.\" \"That's wonderful!\" the artist exclaimed. \"What's the bad news?\" With concern, the gallery owner replied:\"The guy was your doctor.\"\n",
      "145\n",
      "A blonde, brunette, and a red head are all lined up to be shot to death by a firing squad. The brunette shouts, \"Tornado!\" and the riflemen turn around to see the tornado. It isn't there, and the brunette uses that time to escape. The red head yells, \"Lightning!\" and the riflemen again turn to see the disaster, yet there is no disaster and the red head escapes. The blonde yells, \"Fire!\" The riflemen do.\n",
      "71\n",
      "At a recent Sacramento PC Users Group meeting, a company was demonstrating its latest speech- recognition software. A representative from the company was just about ready to start the demonstration and asked everyone in the room to quiet down. Just then, someone in the back of the room yelled, \"Format C: Return.\" Someone else chimed in: \"Yes, Return.\" Unfortunately, the software worked.\n",
      "140\n",
      "Chuck Norris' calendar goes straight from March 31st to April 2nd; no one fools Chuck Norris.\n",
      "126\n",
      "A Briton, a Frenchman and a Russian are viewing a painting of Adam and Eve frolicking in the Garden of Eden. \"Look at their reserve, their calm,\" muses the Brit. \"They must be British.\" \"Nonsense,\" the Frenchman disagrees. \"They're naked, and so beautiful. Clearly, they are French.\" \"No way! They have no clothes and no shelter,\" the Russian points out, \"They have only an apple to eat, and they are being told they live in a paradise. Obviously, they are Russian.\"\n",
      "148\n",
      "Recently a teacher, a garbage collector, and a lawyer wound up together at the Pearly Gates. St. Peter informed them that in order to get into Heaven, they would each have to answer one question. St. Peter addressed the teacher and asked, \"What was the name of the ship that crashed into the iceberg? They just made a movie about it.\" The teacher answered quickly, \"That would be the Titanic.\" St. Peter let him through the gate. St. Peter turned to the garbage man and, figuring Heaven didn't really need all the odors that this guy would bring with him, decided to make the question a little harder: \"How many people died on the ship?\" Fortunately for him, the trash man had just seen the movie. \"1,228,\" he answered. \"That's right! You may enter.\" St. Peter turned to the lawyer: \"Name them.\"\n"
     ]
    }
   ],
   "source": [
    "# Printing top predictions\n",
    "for uid, user_ratings in take(5,top_n.items()):\n",
    "    print(\"For User\",uid)\n",
    "    for  (iid, _) in user_ratings:\n",
    "        print(iid)\n",
    "        ids = iid-1\n",
    "        print(jokes.loc[ids,\"Joke\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**An example to find out how the user 100 would rate the Joke 123:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=100, iid=123, r_ui=None, est=-5.651491439108761, details={'actual_k': 3, 'was_impossible': False})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = KNN_Algo.predict(100, 123)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.651491439108761"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tuning the Algorithm Parameters\n",
    "\n",
    "Surprise provides a GridSearchCV class analogous to GridSearchCV from scikit-learn.\n",
    "\n",
    "With a dict of all parameters, GridSearchCV tries all the combinations of parameters and reports the best parameters for any accuracy measure\n",
    "\n",
    "For example, you can check which similarity metric works best for your data in memory-based approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "4.648297472031535\n",
      "{'sim_options': {'name': 'cosine', 'min_support': 3, 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "sim_options = {\n",
    "    \"name\": [\"msd\", \"cosine\"],\n",
    "    \"min_support\": [3, 4, 5],\n",
    "    \"user_based\": [False, True],\n",
    "}\n",
    "\n",
    "param_grid = {\"sim_options\": sim_options}\n",
    "\n",
    "jokes_gs = GridSearchCV(KNNWithMeans, \n",
    "                  param_grid, \n",
    "                  measures=[\"rmse\", \"mae\"], \n",
    "                        cv=3)\n",
    "\n",
    "jokes_gs.fit(jokes_data)\n",
    "\n",
    "print(jokes_gs.best_score[\"rmse\"])\n",
    "print(jokes_gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Model Based\n",
    "\n",
    "The second category covers the Model based approaches, which involve a step to reduce or compress the large but sparse user-item matrix.\n",
    "\n",
    "**Dimensionality Reduction**\n",
    "\n",
    "In the user-item matrix, there are two dimensions:\n",
    "\n",
    "> 1. The number of users\n",
    "2. The number of items\n",
    "\n",
    "If the matrix is mostly empty, reducing dimensions can improve the performance of the algorithm in terms of both space and time. You can use various methods like matrix factorization or autoencoders to do this.\n",
    "\n",
    "Matrix factorization can be seen as breaking down a large matrix into a product of smaller ones. This is similar to the factorization of integers, where 12 can be written as 6 x 2 or 4 x 3. In the case of matrices, a matrix A with dimensions m x n can be reduced to a product of two matrices X and Y with dimensions m x p and p x n respectively.\n",
    "\n",
    "The reduced matrices actually represent the users and items individually. The m rows in the first matrix represent the m users, and the p columns tell you about the features or characteristics of the users. The same goes for the item matrix with n items and p characteristics.\n",
    "\n",
    "One of the popular algorithms to factorize a matrix is the [singular value decomposition (SVD)](https://en.wikipedia.org/wiki/Singular_value_decomposition) algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_62",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the trainset:\n",
      "RMSE: 0.6749\n",
      "Accuracy on the testset:\n",
      "RMSE: 0.6694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6693703976669881"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset,accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load the in-built movielens-100k dataset (download it if needed).\n",
    "ml_data = Dataset.load_builtin('ml-100k')\n",
    "raw_ratings = ml_data.raw_ratings  \n",
    "\n",
    "\n",
    "# 75% trainset, 25% testset                                                \n",
    "threshold = int(.75 * len(raw_ratings))                                     \n",
    "trainset_raw_ratings = raw_ratings[:threshold]                             \n",
    "test_raw_ratings = raw_ratings[threshold:]     \n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "SVD_Algo = SVD() # default epoch: 20, lr_all = 0.005, reg_all = 0.02\n",
    "\n",
    "trainset = ml_data.build_full_trainset()   \n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "SVD_Algo.fit(trainset)\n",
    "\n",
    "                                                                                   \n",
    "                                                                           \n",
    "# now test on the trainset                                                 \n",
    "trainset = ml_data.construct_testset(trainset_raw_ratings)                     \n",
    "predictions = SVD_Algo.test(trainset)                                           \n",
    "print('Accuracy on the trainset:')                                         \n",
    "accuracy.rmse(predictions)                                                 \n",
    "                                                                           \n",
    "# now test on the testset                                                  \n",
    "testset = ml_data.construct_testset(test_raw_ratings)                         \n",
    "predictions = SVD_Algo.test(testset)                                           \n",
    "print('Accuracy on the testset:')                                          \n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For model-based approaches, we can use Surprise to check which values for the following factors work best:\n",
    "\n",
    "- **n_epochs** is the number of iterations of SGD, which is basically an iterative method used in Statistics to minimize a function.\n",
    "- **lr_all** is the learning rate for all parameters, which is a parameter that decides how much the parameters are adjusted in each iteration.\n",
    "- **reg_all** is the regularization term for all parameters, which is a penalty term added to prevent overfitting.\n",
    "\n",
    "**Note: Keep in mind that there won’t be any similarity metrics in matrix factorization algorithms as the latent factors take care of similarity among users or items.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRID SEARCH BEGIN...\n",
      "GRID SEARCH END...\n",
      "CPU times: user 25.9 s, sys: 64.2 ms, total: 26 s\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import random                                                              \n",
    "                                                                           \n",
    "# Load your full dataset.                                                  \n",
    "ml_data = Dataset.load_builtin('ml-100k')                                     \n",
    "raw_ratings = ml_data.raw_ratings                                             \n",
    "                                                                           \n",
    "# shuffle ratings if you want                                              \n",
    "random.shuffle(raw_ratings)                                                \n",
    "                                                                           \n",
    "# 75% trainset, 25% testset                                                \n",
    "threshold = int(.75 * len(raw_ratings))                                     \n",
    "trainset_raw_ratings = raw_ratings[:threshold]                             \n",
    "test_raw_ratings = raw_ratings[threshold:]                                 \n",
    "                                                                           \n",
    "ml_data.raw_ratings = trainset_raw_ratings  # data is now your trainset                                                           \n",
    "                                                                           \n",
    "# Select your best algo with grid search. Verbosity is buggy, I'll fix it. \n",
    "print('GRID SEARCH BEGIN...')                                                    \n",
    "param_grid = {\n",
    "    \"n_epochs\": [5, 10],\n",
    "    \"lr_all\": [0.002, 0.005],\n",
    "    \"reg_all\": [0.4, 0.6]\n",
    "}\n",
    "\n",
    "movie_gs = GridSearchCV(SVD, \n",
    "                        param_grid, \n",
    "                        measures=[\"rmse\", \"mae\"], \n",
    "                        cv=3)\n",
    "\n",
    "movie_gs.fit(ml_data)\n",
    "print('GRID SEARCH END...')                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "RO_65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the trainset:\n",
      "RMSE: 0.9375\n",
      "Accuracy on the testset:\n",
      "RMSE: 0.9691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9691089967100166"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_final = movie_gs.best_estimator['rmse']                                  \n",
    "                                                                           \n",
    "# retrain on the whole train set                                           \n",
    "trainset = ml_data.build_full_trainset()                                      \n",
    "ml_final.fit(trainset)                                                       \n",
    "                                                                           \n",
    "# now test on the trainset                                                 \n",
    "testset = ml_data.construct_testset(trainset_raw_ratings)                     \n",
    "predictions = ml_final.test(testset)                                           \n",
    "print('Accuracy on the trainset:')                                         \n",
    "accuracy.rmse(predictions)                                                 \n",
    "                                                                           \n",
    "# now test on the testset                                                  \n",
    "testset = ml_data.construct_testset(test_raw_ratings)                         \n",
    "predictions = ml_final.test(testset)                                           \n",
    "print('Accuracy on the testset:')                                          \n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Summary",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this activity, we learnt:\n",
    "> - Collaborative filtering \n",
    "    - User Based Collaborative Filtering\n",
    "    - Item Based Collaborative Filtering\n",
    "> - Distance Measures\n",
    "    - Euclidean distance\n",
    "    - Cosine similarity\n",
    "> - Collaborative Filtering Algorithms\n",
    "    - Memory Based\n",
    "        - KNN\n",
    "    - Model Based\n",
    "        - SVD\n",
    "> - Recommendations using Collaborative Filtering.\n",
    "> - Hyper parameter tuning using cross validation and grid search.\n",
    "\n",
    "References :\n",
    "\n",
    "> - https://realpython.com/build-recommendation-engine-collaborative-filtering/\n",
    "    - https://surprise.readthedocs.io/en/stable/getting_started.html\n",
    "\n",
    "Datasets :\n",
    "> - http://eigentaste.berkeley.edu/dataset/\n",
    "    - https://github.com/caserec/Datasets-for-Recommneder-Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
